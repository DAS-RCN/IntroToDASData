{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/eileenrmartin/IntroToDASData/blob/master/Forge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://drive.google.com/uc?id=1o51pGoz29QwmTx4NhqDNyAf-a2zdXjjJ\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook created by Nate Lindsey (Stanford). Assistance with editing provided by Eileen Martin (Virginia Tech), Ariel Lellouch (Stanford), Ethan Williams (Caltech), Bin Luo (Colorado School of Mines), and Veronica Rodriguez Tribaldos (Lawrence Berkleey National Lab).\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, we will demonstrate how we can access and analyze publically available DAS data. In this example, we will look at a vertical DAS (and colocated geophone) dataset from the monitoring well at the US Department of Energy's Enhanced Geothermal System FORGE Project in Utah. After checking out the data, we will analyze the passive seismic background noise levels and examine an earthquake wavefield.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "### The FORGE Project\n",
    "The Frontier Observatory for Research in Geothermal Energy (FORGE) project funded by the US Department of Energy and hosted by the University of Utah is creating an underground laboratory for developing and testing innovative tools and stimulation techniques for developing enhanced geothermal system (EGS) reservoirs. The R&D focus is on strengthening understanding of the key mechanisms controlling EGS success, specifically how to initiate and sustain fracture networks in basement rock formations through innovative drilling techniques, reservoir stimulation techniques, well connectivity and flow-testing efforts, and novel continuous geophysical monitoring methodologies.\n",
    "\n",
    "#####  Learn more about FORGE:\n",
    "- [Univ. Utah FORGE site](https://utahforge.com/)\n",
    "- [DOE FORGE site](https://www.energy.gov/eere/forge/forge-home)\n",
    "- [Phase 2C Report from GDR](https://constantine.seis.utah.edu/datasets.html)\n",
    "\n",
    "### Public Archive of FORGE (Phase-II) Data\n",
    "As of July 2020, the FORGE (Phase-II) data are publically available in the archive [here](https://constantine.seis.utah.edu/datasets.html). This site provides access to the seismic data generated by the FORGE project. The data distribution is made possible by the University of Utah's Center for High Performance Computing (CHPC). Near the FORGE project's completion, the waveform data collected here is planned to be transferred to the Incorporated Research Institutions for Seismology Data Management Center (IRIS DMC).\n",
    "\n",
    "##### The FORGE data include:\n",
    "- Continuous Silixa iDAS Carina DAS data for 1280 channels from April - May 2019 [[Link to DAS Download Script]](https://constantine.seis.utah.edu/files/get_all_silixa.sh). \n",
    "- Continuous Schlumberger three-component geophone data from a 12-station array. [[Link to Geophone Download Script]](https://constantine.seis.utah.edu/files/get_all_slb.sh)\n",
    "- $\\underline{Note}$: There are a few “gaps” early in the DAS data, and acquisition parameters changed along the way. Recommended to use data after April 22nd.\n",
    "- For the 2020 DAS Workshop and Tutorial, please use the pre-downloaded DAS and geophone data to avoid overloading the Utah servers.\n",
    "\n",
    "### Setup environment\n",
    "Many of the Python packages we'll use are already available in Colab. We are going to use [Obspy](https://docs.obspy.org/) throughout, so we first need to install this package via pip. We also need to download a few auxiliary files from the web using wget commands. The FORGE DAS data are accessible through the Utah sites (links above). There is also a Python library with some modules available via Google Drive that we have made available for this workshop. To run a bash (command-line) command like wget in a Jupyter notebook on Colab, use an ! before the command. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# This will take a few minutes, but only needs to be run once.\n",
    "#\n",
    "#get obspy, gdown\n",
    "!pip -q install obspy gdown\n",
    "#some das utilities\n",
    "!gdown -q https://drive.google.com/uc?id=1aBEF07MSaCCHSmkHQ4ibq3hZI42lEnVL  -O forgeUtils.py\n",
    "#pre-downloaded FORGE Data for the DAS Workshop\n",
    "!gdown -q https://drive.google.com/uc?id=190ljQs25UyBdnRTGfvkPI7Ovfm11J05T -O forgeData.zip \n",
    "!unzip -o -q forgeData.zip\n",
    "!rm -r __MACOSX\n",
    "!rm -r forgeData.zip\n",
    "#Univ. of Utah scripts to download more FORGE Data, please do not use during the Workshop.\n",
    "!gdown -q https://drive.google.com/uc?id=1SZCKJwod3APDAIlxLAe6RkqXFAC6z3EW -O get_all_silixa.sh\n",
    "!gdown -q https://drive.google.com/uc?id=1oHF3unxARvFh31q-EhLDRyr02ngVdC5N -O get_all_slb.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this every time you restart\n",
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import obspy\n",
    "import forgeUtils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Check out how easy this can be..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def easy(): \n",
    "    \n",
    "    #setup\n",
    "    import obspy\n",
    "    import matplotlib.pyplot as plt\n",
    "    import forgeUtils as utils\n",
    "\n",
    "    #parameters\n",
    "    gaugelength     = 10.0 \n",
    "    dx_in_m         = 1.02\n",
    "    das_units       = 'n$\\epsilon$/s'\n",
    "    geophone_units  = 'm/s^2'\n",
    "    geophone_fac    = 2.333e-7\n",
    "    fo_start_ch     = 197\n",
    "    start = obspy.UTCDateTime(2019,4,24,22,24,27.3) # perforation #1 for demonstration\n",
    "    end   = obspy.UTCDateTime(2019,4,24,22,24,27.8)\n",
    "\n",
    "    #download\n",
    "    files_das = utils.download(utils.get_paths('das',[start,end]), switch='workshop')\n",
    "    files_geo = utils.download(utils.get_paths('geophone',[start,end]), switch='workshop')\n",
    "        \n",
    "    #read\n",
    "    das   = utils.read(files_das,dx_in_m=dx_in_m,timerange=[start,end],units=das_units,fo_start_ch=fo_start_ch)\n",
    "    geo   = utils.read(files_geo,timerange=[start,end],fac=geophone_fac,units=geophone_units)\n",
    "        \n",
    "    #process -- this has already been applied for Workshop\n",
    "    #das = utils.medianSubtract(das)\n",
    "    #das.filter('bandpass',freqmin=10,freqmax=150)\n",
    "    #geo.filter('bandpass',freqmin=10,freqmax=150)\n",
    "    \n",
    "    return das,geo\n",
    "\n",
    "#####################################\n",
    "das,geo = easy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "fig = utils.image(das,style=1,skip=1,physicalFiberLocations=True,clim=[-6,6])\n",
    "fig = utils.wiggle(geo.select(channel='Z'),color='k',skip=1,style=1,scale=1.,fig=fig)\n",
    "plt.xlim([.3,.99]);\n",
    "plt.ylim([0.,.4]);\n",
    "plt.xlabel('Distance relative to wellhead [km]');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This half second of DAS recording shows the full fiber length plotted for the first perforation shot on April 24, 2019. Geophones are plotted on top as white traces. The P-wave arrives at the bottom of the well and propagates up the well, followed by a second P-wave ~0.15 s later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Download FORGE Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do I automatically download DAS files from FORGE (Phase-II) archive?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the time range of interest for the event or continuous time period. We can build up a catalog dictionary of events when we know there will be some action. To find more events you could look through the FORGE Report, or use a tool like [IRIS Wilber3](www.wilber3.com) to find some earthquakes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catalog\n",
    "events = {'0':{'eventName':'perf1','eventTime':obspy.UTCDateTime(2019,4,24,22,24,27.3)},\n",
    "          '1':{'eventName':'perf2','eventTime':obspy.UTCDateTime(2019,4,29,16,50,0)}}\n",
    "\n",
    "# Event example\n",
    "duration = 1; # seconds\n",
    "start = events['0']['eventTime']\n",
    "end   = start+duration\n",
    "\n",
    "# Continuous example\n",
    "# start = obspy.UTCDateTime(2019,5,2,0,12,0)\n",
    "# end = obspy.UTCDateTime(2019,5,2,0,13,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert time range to the unique download urls for either 'das' or 'geophone' using the $\\textbf{get_paths}$ method. Then request each file url using wget in batch mode using the $\\textbf{download}$ method. The data will be downloaded to a $\\textbf{forgeData}$ directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = utils.get_paths('das',[start,end])\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_das = utils.download(urls,switch='workshop')\n",
    "files_das"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for geophone data, so we have it for later comparisons. The geophone data will be downloaded to the same new directory called $\\textbf{forgeData}$, but we can tell these apart by their different suffixes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls2 = utils.get_paths('geophone',[start,end])\n",
    "urls2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_geo = utils.download(urls2,switch='workshop')\n",
    "files_geo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are presently many DAS data formats including SEG-Y, Mini-SEED, TDMS, HDF-5, and PRODML. The array datatype, size of individual files, and desire to be able to slice sections of the array in space and time are driving the community to adopt heirarchical dataformats (HDF-5, PRODML). However, the standard is yet to be set (as of July 2020). The FORGE Project (Phase-II) recorded SEG-Y data files. SEG-Y files are organized Streams of seismic waveform Traces with individual trace headers describing channel parameters. This is similar to Mini-SEED."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. QA/QC the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do I check that the data I downloaded are OK?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Obspy, try reading in the first SEG-Y file downloaded above, and examine the stream and a trace header (stats).\n",
    "\n",
    "$\\textit{Note: the normal obspy read function will not work, so use obspy.io.segy.core._read_segy() instead}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy.io.segy.core\n",
    "das = obspy.io.segy.core._read_segy(files_das[0],format='segy',unpack_trace_headers=True)\n",
    "print(das[:15].__str__(extended=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(das[15].stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to find out some additional information about this experiment before we can proceed:\n",
    "- The Phase 2C Report  states that the DAS data were recorded with a Silixa iDAS interrogator which used a $\\textbf{10-m gauge length}$ with a  $\\textbf{1.02 m channel spacing}$ (Section 2.2, p.5, B.III). \n",
    "- The data are provided in $\\textbf{nanostrain/second}$ (nm/m/s) (Section 3.4, p.12). This is not what is natively recorded by the Silixa iDAS (optical phase / timesample). There is a scalar conversion from optical phase per timesample to nanostrain per second, and the report is effectively saying that this scalar multiplication has already been applied. The analogy here is how a seismometer records a voltage in V, but the instrument manufacturer may deliver data in m/s, having already applied the scalar V/m/s conversion factor.\n",
    "- Geometry: The geometry of DAS arrays are usually challenging at first. The first channel is probably located inside the IU, not at the IU/cable connection point. \"Tap testing\" is a good way to establish $\\textbf{\"Key Locations\"}$. It is also a good practice to only trust linear fiber lengths between key locations. At FORGE, the key locations would be the wellhead and the channel that corresponds to the instrument/cable connection point. Additionally, it is possible to record DAS data beyond the physical cable's far end. Channels before and after the physical cable length should be masked in preprocessing. In Silixa's Survey Report (Figure 3, p.9), a tap test is described and the following fiber map is delivered:\n",
    "<img src=\"https://drive.google.com/uc?id=1muAsnQIurYLtxT1HnLx6zSKyRVek9n0d\" width=600px> <img src=\"https://drive.google.com/uc?id=1r1rksUisMZcWhvOlVwSg9aTUQ08uqHo6\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From this information, we can gather that the linear fiber length between the two key points is 996.51 m (1037.8 m - 41.29m), which is equivalent to $\\textbf{977 channels}$ (996.51 m/1.02m/channel). The wellhead's key location is not noted, but we can use this relative distance to find it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaugelength = 10.0 #m\n",
    "das_units = 'n$\\epsilon$/s'\n",
    "dx_in_m = 1.02 #m/channel\n",
    "fo_distance_in_well = 996.51 #m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the geophone data, we are told on the Utah data access webpage: \"The following is downhole geophone data collected by Schlumberger....the units are bits. To convert to acceleration ($m/s^2$) multiply by $2.333 x 10^{-7}$.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geophone_fac = 2.333e-7\n",
    "geophone_units = 'm/s^2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this info, we can populate trace headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "das = utils.populate_das_segy_trace_headers(das,dx_in_m=dx_in_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the first Trace again, to verify that the channel and location info are correct. Note that these pieces of info are hard-coded for this experiment in the utils.py file. The \"station\" is the 5-digit Trace index in the Stream, while the \"location\" is the position along the fiber in meters. The \"channel\" is a string that could be providing an orientation of the single component in the horizontal direction, or in this case is \"Z\" for vertical. In order to plot the \"section\" plot in the next section the \"distance\" info needs to be populated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(das[15].stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $\\textbf{read}$ method is available in the forgeUtils module to perform Trace header population, merging, and trimming on any list of das or geophone files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "das = utils.read(files_das,dx_in_m=dx_in_m,timerange=[start,end],units=das_units)\n",
    "\n",
    "# Note: If you do not add in the timerange param you will load the full timerange downloaded. \n",
    "#  You can also change the timerange at this point to only read in part of the downloaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "das[10].stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...It also works for geophone files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = utils.read(files_geo,timerange=[start,end],fac=geophone_fac,units=geophone_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Restart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple process containing everything needed to $\\textbf{setup}$ for FORGE from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(start,end):    \n",
    "    gaugelength     = 10.0\n",
    "    dx_in_m         = 1.02\n",
    "    das_units       = 'n$\\epsilon$/s'\n",
    "    geophone_units  = 'm/s^2'\n",
    "    geophone_fac    = 2.333e-7\n",
    "    fo_distance_in_well = 996.51 #m\n",
    "    fo_start_ch     = 197\n",
    "    files_das = utils.download(utils.get_paths('das',[start,end]),switch='workshop')\n",
    "    files_geo = utils.download(utils.get_paths('geophone',[start,end]),switch='workshop')\n",
    "    das   = utils.read(files_das,dx_in_m=dx_in_m,timerange=[start,end],fo_start_ch=fo_start_ch,units=das_units)\n",
    "    geo   = utils.read(files_geo,timerange=[start,end],fac=geophone_fac,units=geophone_units)\n",
    "    return das,geo,gaugelength,dx_in_m,fo_distance_in_well\n",
    "    \n",
    "########\n",
    "time0 = obspy.UTCDateTime(2019,4,24,22,24,27.3)\n",
    "time1 = obspy.UTCDateTime(2019,4,24,22,24,27.8)\n",
    "das,geo,gaugelength,dx_in_m,fo_distance_in_well = setup(time0,time1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish Geometry\n",
    "Before we analyze the data we want to establish the actual key location of the vertical well section of DAS channels in the dataset. We were told that the fo_distance_in_well = 996.51 m. We can use the noise characteristics of a sample data to find where distance makes the best fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distances -- move fo_start_in_m to the wellhead position\n",
    "fo_start_in_m = 50 #m <---- \n",
    "fo_end_in_m = fo_start_in_m + fo_distance_in_well\n",
    "fo_start_in_ch = int(fo_start_in_m/dx_in_m)\n",
    "fo_end_in_ch = int(fo_end_in_m/dx_in_m)\n",
    "print('First channel is '+str(fo_start_in_ch))\n",
    "\n",
    "# interactively plot\n",
    "fig = utils.image(das,style=1,skip=1,clim=[-200,200])\n",
    "plt.axvline(fo_start_in_m*dx_in_m/1000,color='gold',lw=3)\n",
    "plt.axvline(fo_end_in_m*dx_in_m/1000,color='gold',lw=3)\n",
    "plt.xlim([0,1.3]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 plotting methods in the utils package: $\\textbf{wiggle}$ and $\\textbf{image}$.\n",
    "\n",
    "In this $\\textbf{wiggle}$ method you can play with the following parameters: \n",
    "- 'skip' every X ch for speed (=10 by default)\n",
    "- 'style' plots a simple line (=1 by default) or red/blue plot (=2) \n",
    "- 'scale' amplitudes (=1.0 by default) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = utils.wiggle(das,skip=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also overlay the geophones and DAS traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = utils.wiggle(das,skip=30,)\n",
    "fig = utils.wiggle(geo.select(channel='Z'),skip=1,color='r',fig=fig)\n",
    "plt.xlim([-0.2,1.1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the $\\textbf{image}$ method you can play with the following parameters: \n",
    "- 'skip' every X ch for speed (=10 by default)\n",
    "- 'style' modifies the trace normalization, 1 for raw, 2 for trace normalized (=1 by default)\n",
    "- 'clim' clips the colormap to [min,max] (deactivated =[0] by default) \n",
    "- 'physicalFiberLocations' plots the x-axis relative to the wellhead instead of (=False for linear fiber length). Note that the geophone data are located relative to wellhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = utils.image(das,style=1,skip=30,clim=[-200,200],physicalFiberLocations=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as in the wiggle case, we can plot geophone wiggle data over an image by sending the fig handle into the wiggle call and then making sure to fix the x-axis limits after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = utils.image(das,style=2,skip=5,physicalFiberLocations=True)\n",
    "fig = utils.wiggle(geo.select(channel='Z'),skip=1,color='w',scale=1.,fig=fig)\n",
    "plt.xlim([-.2,1.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ! Discuss:\n",
    "\n",
    "$\\textbf{Question}$: Why is QA/QC so important?\n",
    "\n",
    "$\\textbf{Question}$: What are the units of the DAS? What are the units of the geophones?\n",
    "\n",
    "$\\textbf{Question}$: The DAS channel spacing is 1.02 meters, what is the spatial precision?\n",
    "\n",
    "$\\textbf{Question}$: You just began recording DAS with a telecomm cable. How will you establish the physical array geometry? What equipment do you need to bring for the tap test? \n",
    "\n",
    "$\\textbf{Question}$: When would you use a wiggle plot vs. an image plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Noise Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in 30 seconds of continuous, passive recording (no catalogued events documented). This will take about 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time0 = obspy.UTCDateTime(2019,5,2,0,12,0)\n",
    "time1 = obspy.UTCDateTime(2019,5,2,0,12,30)\n",
    "das,geo,gaugelength = utils.setup(time0,time1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute and plot Power Spectral Density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the unfiltered power spectral density (PSD) of a DAS array is a good way to begin to understand DAS background noise as a function of frequency and position. \n",
    "\n",
    "To compute the PSD of the array, pass the stream object to $\\textbf{spectra}$ with the following parameters:\n",
    "- 'units' allows a choice of 'strain' that will integrate the data (default = 'strain-rate')\n",
    "- 'kind' chooses amplitude spectra (='as'), power spectra (='ps'), or power spectral density (='psd', default)\n",
    "- 'trace' if passed, compute for this single trace index only\n",
    "\n",
    "We can pass the computed spectra (numpy.array) to $\\textbf{plotSpectra}$ for plotting. \n",
    "\n",
    "If the full array spectra were computed, then we are going to plot an image, or alternatively we can pass just the computed trace spectra for an individual channel spectra line plot. $\\textbf{plotSpectra}$ has the following parameters: \n",
    "- 'trace' plot for this single trace index only\n",
    "- 'fig' allows input passing of the figure axis back to overlay traces\n",
    "- 'units' keeps track of choice of 'strain' or 'strain-rate' for labeling\n",
    "- 'kind' keeps track of amplitude (='as') or power spectra (='ps'), or PSD (='psd') for labeling\n",
    "- 'clim' for clipping image colorscale (default is [-70,10])\n",
    "- 'cmap' for choosing image colorscale map\n",
    "\n",
    "Compare three trace plots and an image plot of the full array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting traces by index...\n",
    "\n",
    "tr = 20\n",
    "fr,psd = utils.spectra(das.copy(),kind='psd',trace=tr) # compute just the trace\n",
    "fig = utils.plotSpectra(das,fr,psd,clim=[-150,-220],kind='psd',trace=tr)\n",
    "\n",
    "tr = 220\n",
    "fr,psd = utils.spectra(das.copy(),kind='psd',trace=tr)\n",
    "fig = utils.plotSpectra(das,fr,psd,clim=[-150,-220],kind='psd',trace=tr,fig=fig)\n",
    "\n",
    "tr = 1050\n",
    "fr,psd = utils.spectra(das.copy(),kind='psd',trace=tr)\n",
    "fig = utils.plotSpectra(das,fr,psd,clim=[-150,-220],kind='psd',trace=tr,fig=fig)\n",
    "\n",
    "\n",
    "# Plotting image of full array ...\n",
    "\n",
    "fr,psd = utils.spectra(das.copy(),kind='psd') # all channels\n",
    "fig = utils.plotSpectra(das[::20],fr,psd,clim=[-150,-220],kind='psd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot array noise levels as RMS vs. channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Parseval's theorem, we can measure the RMS noise level in strain-rate or the strain over the array to get a sense of the relative amplitudes. [Current industry standards]('file:///Users/nate/Desktop/Measuring%20Sensor%20Performance.pdf') suggest doing this analysis in strain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STRAIN-RATE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_level(stream,units='strain-rate'):\n",
    "    \n",
    "    # compute psd \n",
    "    if units=='strain-rate':\n",
    "        units_plot='20*Log$_{10}$(RMS Strain-rate) [dB rel. 1 $\\epsilon$/s]'\n",
    "        fr,psd_ = utils.spectra(stream.copy(),kind='psd',units='strain-rate') # all channels\n",
    "    elif units=='strain':\n",
    "        units_plot='20*Log$_{10}$(RMS Strain) [dB rel. 1 $\\epsilon$]'\n",
    "        fr,psd_ = utils.spectra(stream.copy(),kind='psd',units='strain') # all channels\n",
    "    \n",
    "    # compute RMS by integrating PSD (in band around f=1 Hz); and then RMS = sqrt(PSD*df)\n",
    "    psd_ = np.exp(psd_/10) # convert 10*log10(psd) to raw psd (already rel. to 1 e)\n",
    "    df =  fr[1]-fr[0] # frequency increment\n",
    "    f_0 = int(1.0/df) # 1 Hz frequency index\n",
    "    f_1 = int(250.0/df) # 250 Hz frequency index\n",
    "    rms_ = np.sqrt(np.sum(psd_[f_0:f_1],axis=0)*df) \n",
    "\n",
    "    #plot\n",
    "    x = np.arange(stream[0].stats.distance,stream[-1].stats.distance,1.02)/1e3 # distances\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(x,20*np.log10(rms_))\n",
    "    plt.title('FORGE DAS Noise Level from f=%.2f-%.2f Hz' % (fr[f_0],fr[f_1]))\n",
    "    plt.xlabel('Distance relative to wellhead [km]')\n",
    "    plt.ylabel(units_plot)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "#\n",
    "noise_level(das,units='strain-rate')\n",
    "plt.ylim([-120,-30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STRAIN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_level(das,units='strain')\n",
    "plt.ylim([-120,-30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot frequency-wavenumber spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fk(stream):\n",
    "    \n",
    "    import numpy as np\n",
    "   \n",
    "    # frequencies\n",
    "    nt = stream[0].stats.npts\n",
    "    dt = stream[0].stats.delta\n",
    "    nyq_f = nt//2\n",
    "    f = np.fft.fftfreq(nt, d=dt)[slice(0,nyq_f)]\n",
    "    \n",
    "    # wavenumbers\n",
    "    dx = stream[1].stats.distance - stream[0].stats.distance\n",
    "    nx = len(stream)\n",
    "    nyq_k = nx//2\n",
    "    k = np.fft.fftshift(np.fft.fftfreq(nx, d=dx))\n",
    "    \n",
    "    # frequency-wavenumber power spectral density\n",
    "    A = np.fft.fftshift(np.fft.fft2(utils.stream2array(stream)/1e9)[:,slice(0,nyq_f)],axes=0)\n",
    "    sp2 = 2*(np.abs(A)**2) / (nt**2)\n",
    "    sp2 = 10*np.log10(sp2)\n",
    "    \n",
    "    return f,k[2:],sp2.T\n",
    "\n",
    "def plotFK(f,k,sp2,vmin=0,vmax=0):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig,ax = plt.subplots(figsize=(10,6))\n",
    "    if vmin==vmax:\n",
    "        plt.imshow(sp2,extent=[max(k),min(k),min(f),max(f),],\n",
    "               aspect='auto',cmap='jet',interpolation=None,origin='lower')\n",
    "    else:\n",
    "        plt.imshow(sp2,extent=[max(k),min(k),min(f),max(f),],\n",
    "               aspect='auto',cmap='jet',interpolation=None,origin='lower',\n",
    "               vmin=vmin,vmax=vmax)\n",
    "    h = plt.colorbar()\n",
    "    h.set_label('Power Spectra [dB] (rel. 1 $(\\epsilon/s)^2$)')\n",
    "    plt.ylabel('frequency [1/s]')\n",
    "    plt.xlabel('wavenumber [1/m]')\n",
    "    plt.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot\n",
    "# Choose DAS channels to include\n",
    "ch0 = 198\n",
    "ch1 = 300\n",
    "\n",
    "# TX\n",
    "fig = utils.image(das,style=2,skip=1,physicalFiberLocations=True,clim=[-0.5,0.5])\n",
    "plt.gca().axvline(das[ch0].stats.distance/1e3,color='w',linestyle='--',lw=3)\n",
    "plt.gca().axvline(das[ch1].stats.distance/1e3,color='w',linestyle='--',lw=3)\n",
    "plt.ylim([10,10.5])\n",
    "\n",
    "# FK\n",
    "f,k,sp2 = fk(das[ch0:ch1])\n",
    "ax = plotFK(f,k,sp2,vmin=-170,vmax=-145)\n",
    "plt.ylim([0,25])\n",
    "plt.xlim([-0.1,0.1])\n",
    "plt.grid()\n",
    "\n",
    "# Add Velocity lines\n",
    "c=600; ax.plot(k,k*c,color='w',linestyle='--');\n",
    "c=1100; ax.plot(k,k*c,color='w',linestyle='-');\n",
    "c=4000; ax.plot(k,k*c,color='w',linestyle='--');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ! Discuss:\n",
    "\n",
    "$\\textbf{Question}$: Why does the noise increase beyond the end of the well (physical distance > 1 km)?\n",
    "\n",
    "$\\textbf{Question}$: Why do a few channels have anomalously high PSD values inside the well? Hint: Is this seismic or optical noise?\n",
    "\n",
    "$\\textbf{Question}$: What causes the 18 - 20 Hz noise?\n",
    "\n",
    "$\\textbf{Question}$: For the FORGE DAS array, what type of seismic waves would plot in FK-space at positive wavenumber and positive frequency?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Study an Earthquake "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make up a catalog\n",
    "catalog = {'0' : {'eventName':'perf1','eventTime':obspy.UTCDateTime(2019,4,24,22,24,27.3)},\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load one event\n",
    "time0 = catalog['0']['eventTime']\n",
    "time1   = time0+0.5\n",
    "das,geo,gaugelength = utils.setup(time0,time1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: \n",
    "The data for event0 in the catalog defined is already downloaded, pre-filtered with a median subtraction and bandpass filtered from 10 - 150 Hz (you should see this in the FK plot!). Other events would need similar treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose DAS channels to include\n",
    "ch0 = 500\n",
    "ch1 = 1150\n",
    "\n",
    "# TX\n",
    "fig = utils.image(das,style=2,skip=1,physicalFiberLocations=True,clim=[-0.5,0.5])\n",
    "fig = utils.wiggle(geo.select(channel='Z'),style=1,skip=1,scale=2,fig=fig)\n",
    "plt.gca().axvline(das[ch0].stats.distance/1e3,color='w',linestyle='--',lw=3)\n",
    "plt.gca().axvline(das[ch1].stats.distance/1e3,color='w',linestyle='--',lw=3)\n",
    "plt.xlim([0.2,1.])\n",
    "\n",
    "# FK\n",
    "f,k,sp2 = fk(das[ch0:ch1])\n",
    "ax = plotFK(f,k,sp2,vmin=-160,vmax=-138)\n",
    "plt.ylim([0,300])\n",
    "plt.xlim([-0.15,0.15])\n",
    "c=-4300; ax.plot(k,k*c,color='w',linestyle='--');\n",
    "c=3e8; ax.plot(k,k*c,color='w',linestyle='--');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ! Discuss\n",
    "\n",
    "$\\textbf{Question}$: Describe the wave propagation for stimulation microearthquakes to the surface along the well path.\n",
    "\n",
    "$\\textbf{Question}$: Estimate the P-wave and S-wave speed profile for the well? Describe all assumptions.\n",
    "\n",
    "$\\textbf{Question}$: What causes the zero wavenumber noise? Describe how you could remove this noise.\n",
    "\n",
    "$\\textbf{Question}$: If you wanted to detect more earthquakes using DAS, how could you go about using the array to do this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
